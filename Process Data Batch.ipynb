{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".\\\\data\\\\\"\n",
    "\n",
    "#filename = \"2018-06-20-10-44-11.tdms\"\n",
    "#keyence_filename= \"2018-06-20-10-44-18-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-2445, air, slow\n",
    "#filename = \"2018-07-12-18-36-41.tdms\"\n",
    "#keyence_filename= \"2018-07-12-18-36-56-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-2445, air, fast\n",
    "#filename = \"2018-07-12-18-51-08.tdms\"\n",
    "#keyence_filename= \"2018-07-12-18-51-17-KEYENCE.tdms\"\n",
    "\n",
    "#filename = \"2018-07-17-10-17-29.tdms\"  # SLC-2445, vac, fast\n",
    "#filename = \"2018-07-17-09-45-52.tdms\" # SLC-2445, vac, slow\n",
    "#keyence_filename = None\n",
    "\n",
    "# SLC-1730, air, slow\n",
    "#filename = \"2018-07-25-10-58-32.tdms\"\n",
    "#keyence_filename= \"2018-07-25-10-58-24-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-1730, air, fast\n",
    "#filename = \"2018-07-25-11-13-44.tdms\"\n",
    "#keyence_filename= \"2018-07-25-11-13-50-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-1730, air, fast\n",
    "#filename = \"2018-07-26-10-30-38.tdms\"\n",
    "#keyence_filename= \"2018-07-26-10-31-06-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-1730, air, slow\n",
    "#filename = \"2018-07-26-10-44-20.tdms\"\n",
    "#keyence_filename= \"2018-07-26-10-44-40-KEYENCE.tdms\"\n",
    "\n",
    "# SLC-1730, vac, 24hrs\n",
    "filename = \"2018-07-26-14-39-24.tdms\"\n",
    "keyence_filename= None\n",
    "\n",
    "# SLC-2445, vac, 72hrs\n",
    "#filename = \"2018-07-27-14-45-18.tdms\"\n",
    "#keyence_filename= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_utils\n",
    "import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "reload(batch_utils)\n",
    "reload(data_tools)\n",
    "\n",
    "dry_run = False\n",
    "\n",
    "full_data, info = batch_utils.load_data(filename, keyence_filename, suffix=\"full_data\")\n",
    "\n",
    "batch_utils.print_lengths(full_data, \"Full dataset:\")\n",
    "\n",
    "print(\"Round the position to 3dp\")\n",
    "full_data['position']['round'] = list(np.around(full_data['position']['data'], 2))\n",
    "\n",
    "print(\"Initialise the transition time\")\n",
    "full_data['set_point']['trans'] = [None,] * len(full_data['set_point']['time'])\n",
    "\n",
    "print(\"Calculate data rates\")\n",
    "rate = data_tools.data_rates(full_data)\n",
    "pprint(rate)\n",
    "\n",
    "\n",
    "print(\"Chopping up the data!\")\n",
    "slices = list(range(0, len(full_data['set_point']['time']), 1000))\n",
    "print(\"Got {} slices\".format(len(slices)))\n",
    "slices.append(-1)\n",
    "#pprint(slices)\n",
    "\n",
    "progress = FloatProgress(max=len(slices)-1)\n",
    "display(progress)\n",
    "\n",
    "for i, j in zip(slices, slices[1:]):\n",
    "    \n",
    "    print(\"\\n\\nGetting the next slice {} to {}\".format(i, j))\n",
    "    batch_utils.print_lengths(full_data, \"Full dataset:\")\n",
    "    \n",
    "    limits = [full_data['set_point']['time'][i], full_data['set_point']['time'][j]]\n",
    "    print(\"Using limits:\")\n",
    "    pprint(limits)\n",
    "    \n",
    "    data = dict(zip(full_data.keys(), [data_tools.truncate(limits, full_data[k]) for k in full_data]))\n",
    "    batch_utils.print_lengths(data, \"Truncated dataset:\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "\n",
    "    print(\"Calculating transition time\")\n",
    "    p = FloatProgress()\n",
    "    display(p)\n",
    "\n",
    "    if not dry_run: \n",
    "        batch_utils.calculate_trans(data, p)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "    print(\"Calculating differences\")\n",
    "    p = FloatProgress()\n",
    "    display(p)\n",
    "\n",
    "    diff_pairs = [\n",
    "        (['position', 'data'],            ['set_point', 'data'])\n",
    "        ]\n",
    "\n",
    "    if keyence_filename is not None:\n",
    "        diff_pairs.extend([\n",
    "        (['keyence', ['data1', 'data2']], ['set_point', 'data']),\n",
    "        (['keyence', ['data1', 'data2']], ['position',  'data']),\n",
    "        ])\n",
    "\n",
    "    if not dry_run: \n",
    "        data_tools.calculate_differences(diff_pairs, data, progress=p)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "    print(\"Calculating masks\")\n",
    "    p = FloatProgress()\n",
    "    display(p)\n",
    "\n",
    "    mask_pairs = [('position', 'set_point')]\n",
    "    jitter = rate['position']\n",
    "\n",
    "    if keyence_filename is not None:\n",
    "        mask_pairs.extend([('keyence',  'set_point')])\n",
    "        jitter = max([rate['position'], rate['keyence']])\n",
    "\n",
    "    mask_margin = [datetime.timedelta(seconds = - (jitter)),\n",
    "                   datetime.timedelta(seconds = -(0.5 - jitter))]\n",
    "\n",
    "    if not dry_run: \n",
    "        data_tools.generate_mask(mask_pairs, mask_margin, data, progress=p)\n",
    "\n",
    "    print(\"Done!\")    \n",
    "    \n",
    "    print(\"Storing the data\")\n",
    "    batch_utils.store_data(data, filename, keyence_filename, suffix=\"proc_data_part_{}-{}\".format(i,j), info=info)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    progress.value += 1\n",
    "\n",
    "print(\"Finished processing!\")\n",
    "progress.value = progress.max\n",
    "\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "print(\"Merging data\")\n",
    "p = FloatProgress()\n",
    "display(p)\n",
    "\n",
    "merged_data = None\n",
    "\n",
    "for i, j in zip(slices, slices[1:]):\n",
    "    print(\"\\n\\nGetting the next slice {} to {}\".format(i, j))\n",
    "    \n",
    "    data, info = batch_utils.load_data(filename, keyence_filename, suffix=\"proc_data_part_{}-{}\".format(i,j))\n",
    "    \n",
    "    if merged_data is None:\n",
    "        merged_data = copy.deepcopy(data)\n",
    "    \n",
    "    batch_utils.merge_data(merged_data, data, p)\n",
    "    batch_utils.print_lengths(merged_data, \"After merge:\")\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"Storing the processed data\")\n",
    "if not dry_run: \n",
    "    batch_utils.store_data(data, filename, keyence_filename, suffix=\"proc_data\", info=info)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"The process is complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_tools\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "#limits = [full_data['position']['time'][5000], full_data['position']['time'][5100]]\n",
    "limits = [full_data['set_point']['time'][0], full_data['set_point']['time'][-1]]\n",
    "\n",
    "print(\"Using limits:\")\n",
    "pprint(limits)\n",
    "\n",
    "# Truncate the data\n",
    "trunc_data = dict(zip(full_data.keys(), [data_tools.truncate(limits, full_data[k]) for k in full_data]))\n",
    "\n",
    "print(\"Truncated dataset:\")\n",
    "for k in trunc_data:\n",
    "    print(\"{}: \\t{} points\".format(k, len(trunc_data[k][[*trunc_data[k]][0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what to work with:\n",
    "#data = trunc_data\n",
    "data = full_data\n",
    "\n",
    "print(\"Using dataset:\")\n",
    "for k in data:\n",
    "    print(\"{}: \\t{} points\".format(k, len(data[k][[*data[k]][0]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
